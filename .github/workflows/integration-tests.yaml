name: Integration Tests

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  integration-test:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Start minikube
      uses: medyagh/setup-minikube@master
      with:
        driver: docker
        kubernetes-version: v1.33.0

    - name: Wait for minikube to be ready
      run: |
        kubectl cluster-info
        kubectl get nodes

    - name: Deploy MinIO (S3-compatible storage)
      run: |
        kubectl apply -f tests/integration/manifests/minio.yaml
        
        # Wait for MinIO to be ready
        kubectl wait --for=condition=ready pod -l app=minio --timeout=300s
        kubectl wait --for=condition=complete job/minio-setup --timeout=300s
        
        echo "MinIO is ready"

    - name: Deploy DynamoDB Local
      run: |
        kubectl apply -f tests/integration/manifests/dynamodb-local.yaml
        
        # Wait for DynamoDB Local to be ready
        kubectl wait --for=condition=ready pod -l app=dynamodb-local --timeout=300s
        
        echo "DynamoDB Local is ready"

    - name: Deploy tenant configuration API
      run: |
        kubectl apply -f tests/integration/manifests/api.yaml
        
        # Wait for API to be ready
        kubectl wait --for=condition=ready pod -l app=tenant-config-api --timeout=300s
        
        echo "Tenant configuration API is ready"


    - name: Deploy fake log generators
      run: |
        kubectl apply -f tests/integration/manifests/fake-log-generator.yaml
        kubectl apply -f tests/integration/manifests/fake-log-generator-default.yaml
        
        # Wait for fake log generators to be ready in all namespaces
        kubectl wait --for=condition=ready pod -l app=fake-log-generator --timeout=300s --all-namespaces
        
        echo "Fake log generators are ready in all tenant namespaces"

    - name: Deploy Vector collector
      run: |
        kubectl apply -k k8s/collector/overlays/github
        
        # Wait for Vector DaemonSet to be ready
        kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=vector --timeout=300s
        
        echo "Vector collector is ready"

    - name: Wait for log collection and processing
      run: |
        echo "Waiting for logs to be collected and processed by Vector..."
        sleep 180
        
        # Check Vector logs for any errors
        kubectl logs -l app.kubernetes.io/name=vector --tail=20

    - name: Verify log delivery to MinIO
      run: |
        # Get MinIO pod name
        MINIO_POD=$(kubectl get pod -l app=minio -o jsonpath='{.items[0].metadata.name}')
        echo "MinIO pod: $MINIO_POD"
        
        # Check if log files exist in MinIO bucket
        echo "Checking for log files in MinIO bucket..."
        kubectl exec $MINIO_POD -- ls -la /data/test-logs/
        
        # Verify the expected directory structure exists
        if kubectl exec $MINIO_POD -- ls /data/test-logs/test-cluster/default/fake-log-generator/ > /dev/null 2>&1; then
          echo "✅ Success: Log directory structure found"
        else
          echo "❌ Error: Expected log directory structure not found"
          exit 1
        fi
        
        # Count S3 objects (they appear as directories in MinIO)
        # Check each pod directory for .json.gz objects
        POD_DIRS=$(kubectl exec $MINIO_POD -- ls /data/test-logs/test-cluster/default/fake-log-generator/ 2>/dev/null || echo "")
        
        if [ -z "$POD_DIRS" ]; then
          echo "❌ Error: No pod directories found in MinIO bucket"
          exit 1
        fi
        
        echo "Found pod directories: $POD_DIRS"
        
        # Count .json.gz objects in the first pod directory
        FIRST_POD_DIR=$(echo $POD_DIRS | awk '{print $1}')
        S3_OBJECTS=$(kubectl exec $MINIO_POD -- ls /data/test-logs/test-cluster/default/fake-log-generator/$FIRST_POD_DIR/ 2>/dev/null | grep -c "\.json\.gz" || echo "0")
        
        echo "Found $S3_OBJECTS S3 objects (.json.gz) in pod directory: $FIRST_POD_DIR"
        
        if [ "$S3_OBJECTS" -gt 0 ]; then
          echo "✅ Success: Log objects were created and stored in MinIO"
          echo "✅ Success: Vector is successfully writing logs to S3-compatible storage"
          
          # Verify multiple pods are writing logs
          TOTAL_POD_DIRS=$(echo $POD_DIRS | wc -w)
          echo "✅ Success: Found $TOTAL_POD_DIRS pod directories (from $TOTAL_POD_DIRS fake log generators)"
          
          # Show sample of S3 object names to verify naming pattern
          echo "Sample S3 object names:"
          kubectl exec $MINIO_POD -- ls /data/test-logs/test-cluster/default/fake-log-generator/$FIRST_POD_DIR/ | grep "\.json\.gz" | head -3 || echo "Could not list object names"
          
        else
          echo "❌ Error: No S3 objects (.json.gz) found in MinIO bucket"
          echo "Debug: Contents of pod directory $FIRST_POD_DIR:"
          kubectl exec $MINIO_POD -- ls -la /data/test-logs/test-cluster/default/fake-log-generator/$FIRST_POD_DIR/ || echo "Could not list directory contents"
          exit 1
        fi

    - name: Setup Python for API integration tests
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install API integration test dependencies
      run: |
        pip install -r tests/requirements.txt

    - name: Run true end-to-end S3 processor integration tests
      run: |
        # Start port forwarding for services
        echo "Starting port forwards for integration testing..."
        
        # Port forward MinIO
        kubectl port-forward service/minio 9000:9000 &
        MINIO_PID=$!
        
        # Port forward tenant config API
        kubectl port-forward service/tenant-config-api 8080:8080 &
        API_PID=$!
        
        # Wait for port forwards to be ready
        echo "Waiting for services to be accessible..."
        sleep 15
        
        # Verify services are accessible
        max_retries=30
        
        # Check MinIO
        for i in $(seq 1 $max_retries); do
          if curl -s http://localhost:9000/minio/health/live > /dev/null 2>&1; then
            echo "✅ MinIO accessible on localhost:9000"
            break
          fi
          echo "Waiting for MinIO... ($i/$max_retries)"
          sleep 2
        done
        
        # Check API
        for i in $(seq 1 $max_retries); do
          if curl -s http://localhost:8080/health > /dev/null 2>&1; then
            echo "✅ Tenant Config API accessible on localhost:8080"
            break
          fi
          echo "Waiting for API... ($i/$max_retries)"
          sleep 2
        done
        
        # Run the true end-to-end integration tests
        echo "Running true end-to-end S3 processor integration tests..."
        pytest tests/integration/test_processor_s3_integration.py::TestEndToEndS3ProcessorIntegration -v -m integration --tb=short
        TEST_EXIT_CODE=$?
        
        # Cleanup port forwards
        kill $MINIO_PID $API_PID 2>/dev/null || true
        
        # Exit with test result
        if [ $TEST_EXIT_CODE -eq 0 ]; then
          echo "✅ True end-to-end S3 processor integration tests passed"
        else
          echo "❌ True end-to-end S3 processor integration tests failed"
          exit $TEST_EXIT_CODE
        fi

    - name: Show integration test results
      run: |
        echo "=== True End-to-End Integration Test Summary ==="
        echo "✅ MinIO deployment (source & destination buckets): OK"
        echo "✅ DynamoDB Local deployment: OK"
        echo "✅ Tenant Configuration API deployment: OK"
        echo "✅ Multi-tenant fake log generators deployment: OK" 
        echo "✅ Vector collector deployment: OK"
        echo "✅ Log collection and processing: OK"
        echo "✅ Log delivery to MinIO bucket: OK"
        echo "✅ True end-to-end S3 processor integration tests: OK"
        echo "   - Basic S3 delivery with real API and MinIO"
        echo "   - Multi-delivery configuration (CloudWatch + S3)"
        echo "   - Desired logs filtering validation"
        echo "   - Disabled tenant configuration handling"
        echo "   - Cross-region S3 delivery support"
        echo ""
        echo "True end-to-end integration test completed successfully!"
        echo "All components working together: Vector → MinIO → Processor → API → S3"

    - name: Cleanup (if test fails)
      if: failure()
      run: |
        echo "=== Cleanup and Debug Info ==="
        echo "Pods:"
        kubectl get pods
        echo ""
        echo "Vector logs:"
        kubectl logs -l app.kubernetes.io/name=vector --tail=50 || echo "No Vector logs"
        echo ""
        echo "Fake log generator logs (all namespaces):"
        kubectl logs -l app=fake-log-generator --tail=20 --all-namespaces || echo "No generator logs"
        echo ""
        echo ""
        echo "Tenant config API logs:"
        kubectl logs -l app=tenant-config-api --tail=20 || echo "No API logs"
        echo ""
        echo "MinIO logs:"
        kubectl logs -l app=minio --tail=20 || echo "No MinIO logs"
        echo ""
        echo "DynamoDB Local logs:"
        kubectl logs -l app=dynamodb-local --tail=20 || echo "No DynamoDB Local logs"