name: Integration Tests

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  integration-test:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Start minikube
      uses: medyagh/setup-minikube@master
      with:
        driver: docker
        kubernetes-version: v1.33.0

    - name: Wait for minikube to be ready
      run: |
        kubectl cluster-info
        kubectl get nodes

    - name: Deploy MinIO (S3-compatible storage)
      run: |
        kubectl apply -f tests/integration/manifests/minio.yaml
        
        # Wait for MinIO to be ready
        kubectl wait --for=condition=ready pod -l app=minio --timeout=300s
        kubectl wait --for=condition=complete job/minio-setup --timeout=300s
        
        echo "MinIO is ready"

    - name: Deploy DynamoDB Local
      run: |
        kubectl apply -f tests/integration/manifests/dynamodb-local.yaml
        
        # Wait for DynamoDB Local to be ready
        kubectl wait --for=condition=ready pod -l app=dynamodb-local --timeout=300s
        
        echo "DynamoDB Local is ready"

    - name: Deploy fake log generators
      run: |
        kubectl apply -f tests/integration/manifests/fake-log-generator.yaml
        
        # Wait for fake log generators to be ready
        kubectl wait --for=condition=ready pod -l app=fake-log-generator --timeout=300s
        
        echo "Fake log generators are ready"

    - name: Deploy Vector collector
      run: |
        kubectl apply -k k8s/collector/overlays/github
        
        # Wait for Vector DaemonSet to be ready
        kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=vector --timeout=300s
        
        echo "Vector collector is ready"

    - name: Wait for log collection and processing
      run: |
        echo "Waiting for logs to be collected and processed by Vector..."
        sleep 180
        
        # Check Vector logs for any errors
        kubectl logs -l app.kubernetes.io/name=vector --tail=20

    - name: Verify log delivery to MinIO
      run: |
        # Get MinIO pod name
        MINIO_POD=$(kubectl get pod -l app=minio -o jsonpath='{.items[0].metadata.name}')
        echo "MinIO pod: $MINIO_POD"
        
        # Check if log files exist in MinIO bucket
        echo "Checking for log files in MinIO bucket..."
        kubectl exec $MINIO_POD -- ls -la /data/test-logs/
        
        # Verify the expected directory structure exists
        if kubectl exec $MINIO_POD -- ls /data/test-logs/test-cluster/default/fake-log-generator/ > /dev/null 2>&1; then
          echo "✅ Success: Log directory structure found"
        else
          echo "❌ Error: Expected log directory structure not found"
          exit 1
        fi
        
        # Count S3 objects (they appear as directories in MinIO)
        # Check each pod directory for .json.gz objects
        POD_DIRS=$(kubectl exec $MINIO_POD -- ls /data/test-logs/test-cluster/default/fake-log-generator/ 2>/dev/null || echo "")
        
        if [ -z "$POD_DIRS" ]; then
          echo "❌ Error: No pod directories found in MinIO bucket"
          exit 1
        fi
        
        echo "Found pod directories: $POD_DIRS"
        
        # Count .json.gz objects in the first pod directory
        FIRST_POD_DIR=$(echo $POD_DIRS | awk '{print $1}')
        S3_OBJECTS=$(kubectl exec $MINIO_POD -- ls /data/test-logs/test-cluster/default/fake-log-generator/$FIRST_POD_DIR/ 2>/dev/null | grep -c "\.json\.gz" || echo "0")
        
        echo "Found $S3_OBJECTS S3 objects (.json.gz) in pod directory: $FIRST_POD_DIR"
        
        if [ "$S3_OBJECTS" -gt 0 ]; then
          echo "✅ Success: Log objects were created and stored in MinIO"
          echo "✅ Success: Vector is successfully writing logs to S3-compatible storage"
          
          # Verify multiple pods are writing logs
          TOTAL_POD_DIRS=$(echo $POD_DIRS | wc -w)
          echo "✅ Success: Found $TOTAL_POD_DIRS pod directories (from $TOTAL_POD_DIRS fake log generators)"
          
          # Show sample of S3 object names to verify naming pattern
          echo "Sample S3 object names:"
          kubectl exec $MINIO_POD -- ls /data/test-logs/test-cluster/default/fake-log-generator/$FIRST_POD_DIR/ | grep "\.json\.gz" | head -3 || echo "Could not list object names"
          
        else
          echo "❌ Error: No S3 objects (.json.gz) found in MinIO bucket"
          echo "Debug: Contents of pod directory $FIRST_POD_DIR:"
          kubectl exec $MINIO_POD -- ls -la /data/test-logs/test-cluster/default/fake-log-generator/$FIRST_POD_DIR/ || echo "Could not list directory contents"
          exit 1
        fi

    - name: Setup Python for API integration tests
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install API integration test dependencies
      run: |
        pip install -r tests/requirements.txt

    - name: Run API integration tests
      run: |
        # Start port forwarding for DynamoDB Local in background
        kubectl port-forward service/dynamodb-local 8000:8000 &
        PORT_FORWARD_PID=$!
        
        # Wait for port forward to be ready
        echo "Waiting for DynamoDB Local port forward..."
        sleep 10
        
        # Verify DynamoDB Local is accessible
        max_retries=30
        for i in $(seq 1 $max_retries); do
          if curl -s http://localhost:8000 > /dev/null 2>&1; then
            echo "✅ DynamoDB Local accessible on localhost:8000"
            break
          fi
          echo "Waiting for DynamoDB Local... ($i/$max_retries)"
          sleep 2
        done
        
        if [ $i -eq $max_retries ]; then
          echo "❌ Failed to connect to DynamoDB Local"
          kill $PORT_FORWARD_PID || true
          exit 1
        fi
        
        # Run integration tests
        echo "Running API integration tests..."
        pytest tests/integration/test_api_integration.py -v -m integration --tb=short
        TEST_EXIT_CODE=$?
        
        # Cleanup port forward
        kill $PORT_FORWARD_PID || true
        
        # Exit with test result
        if [ $TEST_EXIT_CODE -eq 0 ]; then
          echo "✅ API integration tests passed"
        else
          echo "❌ API integration tests failed"
          exit $TEST_EXIT_CODE
        fi

    - name: Run S3 delivery unit tests
      run: |
        echo "Running S3 delivery unit tests..."
        pytest tests/unit/test_log_processor.py::TestS3LogDelivery -v --tb=short
        S3_UNIT_EXIT_CODE=$?
        
        if [ $S3_UNIT_EXIT_CODE -eq 0 ]; then
          echo "✅ S3 delivery unit tests passed"
        else
          echo "❌ S3 delivery unit tests failed"
          exit $S3_UNIT_EXIT_CODE
        fi

    - name: Verify S3 delivery configurations in DynamoDB
      run: |
        # Start port forwarding for DynamoDB Local in background
        kubectl port-forward service/dynamodb-local 8001:8000 &
        S3_PORT_FORWARD_PID=$!
        
        # Wait for port forward to be ready
        echo "Waiting for DynamoDB Local port forward for S3 tests..."
        sleep 10
        
        # Verify DynamoDB Local is accessible on alternate port
        max_retries=30
        for i in $(seq 1 $max_retries); do
          if curl -s http://localhost:8001 > /dev/null 2>&1; then
            echo "✅ DynamoDB Local accessible on localhost:8001 for S3 tests"
            break
          fi
          echo "Waiting for DynamoDB Local S3 port... ($i/$max_retries)"
          sleep 2
        done
        
        if [ $i -eq $max_retries ]; then
          echo "❌ Failed to connect to DynamoDB Local for S3 tests"
          kill $S3_PORT_FORWARD_PID || true
          exit 1
        fi
        
        # Create test S3 configurations to verify multi-delivery model
        echo "Creating test S3 delivery configurations..."
        
        # Use Python to create S3 configurations via DynamoDB Local
        python3 << 'EOF'
        import boto3
        import json
        
        # Connect to DynamoDB Local
        dynamodb = boto3.resource(
            'dynamodb',
            endpoint_url='http://localhost:8001',
            region_name='us-east-1',
            aws_access_key_id='test',
            aws_secret_access_key='test'
        )
        
        # Create test table for S3 configs
        table_name = 'ci-s3-delivery-test'
        try:
            table = dynamodb.create_table(
                TableName=table_name,
                KeySchema=[
                    {'AttributeName': 'tenant_id', 'KeyType': 'HASH'},
                    {'AttributeName': 'type', 'KeyType': 'RANGE'}
                ],
                AttributeDefinitions=[
                    {'AttributeName': 'tenant_id', 'AttributeType': 'S'},
                    {'AttributeName': 'type', 'AttributeType': 'S'}
                ],
                BillingMode='PAY_PER_REQUEST'
            )
            table.wait_until_exists()
            
            # Create S3 delivery configuration
            s3_config = {
                'tenant_id': 'ci-s3-test-tenant',
                'type': 's3',
                'bucket_name': 'ci-test-logs-bucket',
                'bucket_prefix': 'cluster-logs/',
                'target_region': 'us-east-1',
                'enabled': True,
                'desired_logs': ['test-app', 'ci-service']
            }
            
            table.put_item(Item=s3_config)
            
            # Verify S3 configuration was created
            response = table.get_item(Key={'tenant_id': 'ci-s3-test-tenant', 'type': 's3'})
            if 'Item' in response:
                print("✅ S3 delivery configuration created successfully")
                print(f"   Bucket: {response['Item']['bucket_name']}")
                print(f"   Prefix: {response['Item']['bucket_prefix']}")
                print(f"   Region: {response['Item']['target_region']}")
                print(f"   Enabled: {response['Item']['enabled']}")
            else:
                print("❌ Failed to create S3 delivery configuration")
                exit(1)
                
            # Create both CloudWatch and S3 for same tenant (multi-delivery test)
            cloudwatch_config = {
                'tenant_id': 'ci-multi-delivery-tenant',
                'type': 'cloudwatch',
                'log_distribution_role_arn': 'arn:aws:iam::123456789012:role/CITestRole',
                'log_group_name': '/aws/logs/ci-multi-delivery-tenant',
                'target_region': 'us-east-1',
                'enabled': True
            }
            
            s3_multi_config = {
                'tenant_id': 'ci-multi-delivery-tenant',
                'type': 's3',
                'bucket_name': 'ci-multi-delivery-bucket',
                'bucket_prefix': 'multi-tenant-logs/',
                'target_region': 'us-east-1',
                'enabled': True
            }
            
            table.put_item(Item=cloudwatch_config)
            table.put_item(Item=s3_multi_config)
            
            # Verify multi-delivery configuration
            cw_response = table.get_item(Key={'tenant_id': 'ci-multi-delivery-tenant', 'type': 'cloudwatch'})
            s3_response = table.get_item(Key={'tenant_id': 'ci-multi-delivery-tenant', 'type': 's3'})
            
            if 'Item' in cw_response and 'Item' in s3_response:
                print("✅ Multi-delivery configuration (CloudWatch + S3) created successfully")
                print(f"   CloudWatch: {cw_response['Item']['log_group_name']}")
                print(f"   S3: {s3_response['Item']['bucket_name']}")
            else:
                print("❌ Failed to create multi-delivery configuration")
                exit(1)
            
            print(f"✅ S3 delivery configuration testing completed successfully")
            
        except Exception as e:
            print(f"❌ Error testing S3 delivery configurations: {str(e)}")
            exit(1)
        EOF
        
        # Cleanup port forward
        kill $S3_PORT_FORWARD_PID || true

    - name: Show integration test results
      run: |
        echo "=== Integration Test Summary ==="
        echo "✅ MinIO deployment: OK"
        echo "✅ DynamoDB Local deployment: OK"
        echo "✅ Fake log generator deployment: OK" 
        echo "✅ Vector collector deployment: OK"
        echo "✅ Log collection and processing: OK"
        echo "✅ Log delivery to MinIO bucket: OK"
        echo "✅ API integration tests with DynamoDB Local: OK"
        echo "✅ S3 delivery unit tests: OK"
        echo "✅ S3 delivery configuration validation: OK"
        echo "✅ Multi-delivery configuration (CloudWatch + S3): OK"
        echo ""
        echo "Integration test completed successfully!"

    - name: Cleanup (if test fails)
      if: failure()
      run: |
        echo "=== Cleanup and Debug Info ==="
        echo "Pods:"
        kubectl get pods
        echo ""
        echo "Vector logs:"
        kubectl logs -l app.kubernetes.io/name=vector --tail=50 || echo "No Vector logs"
        echo ""
        echo "Fake log generator logs:"
        kubectl logs -l app=fake-log-generator --tail=20 || echo "No generator logs"
        echo ""
        echo "MinIO logs:"
        kubectl logs -l app=minio --tail=20 || echo "No MinIO logs"
        echo ""
        echo "DynamoDB Local logs:"
        kubectl logs -l app=dynamodb-local --tail=20 || echo "No DynamoDB Local logs"